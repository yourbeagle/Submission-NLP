# -*- coding: utf-8 -*-
"""Submission NLP dengan Tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lxS91SzxVfh2oC2wsV6TqwNz45OfqC56

**Nama : Wahyu Bagus Wicaksono**

**Grup : M07**

Menginstall Library untuk membersihkan text dari simbol"
"""

import nltk
import re
nltk.download('stopwords')
nltk.download('wordnet')

from nltk.corpus import stopwords
from nltk.stem import LancasterStemmer
from nltk.stem import WordNetLemmatizer

sw = stopwords.words('english')
stemmer = LancasterStemmer()
lemmatizer = WordNetLemmatizer()

replace_puncts = {'`': "'", '′': "'", '“':'"', '”': '"', '‘': "'"}

strip_chars = [',', '.', '"', ':', ')', '(', '-', '|', ';', "'", '[', ']', '>', '=', '+', '\\', '•',  '~', '@', 
 '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', 
 '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', 
 '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', 
 '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]

puncts = ['!', '?', '$', '&', '/', '%', '#', '*','£']

"""membuat fungsi untuk mereplace dan membersihkan text dari simbol"
"""

def clean_text(x):
    x = str(x)
    x = x.lower()
    x = re.sub(r"(https?:\/\/(?:www\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\.[^\s]{2,}|www\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\.[^\s]{2,}|https?:\/\/(?:www\.|(?!www))[a-zA-Z0-9]\.[^\s]{2,}|www\.[a-zA-Z0-9]\.[^\s]{2,})", "url", x)
    for k, v in replace_puncts.items():
        x = x.replace(k, f' {v} ')
        
    for punct in strip_chars:
        x = x.replace(punct, ' ') 
    
    for punct in puncts:
        x = x.replace(punct, f' {punct} ')
        
    x = x.replace(" '", " ")
    x = x.replace("' ", " ")
    x = x.strip()
    return x

def stopwords1(text):
    '''a function for removing the stopword'''
    # removing the stop words and lowercasing the selected words
    text = [word.lower() for word in text.split() if word.lower() not in sw]
    # joining the list of words with space separator
    return " ".join(text)

def stemming(text):    
    '''a function which stems each word in the given text'''
    text = [stemmer.stem(word) for word in text.split()]
    return " ".join(text) 

def lemm(text):    
    text = [lemmatizer.lemmatize(word) for word in text.split()]
    return " ".join(text)

def clean_length(text):
    text = [word for word in text.split() if len(word) > 2]
    return " ".join(text)

def text_processing(X):
    X=X.apply(stopwords1)
    X=X.apply(clean_text)
    X=X.apply(stemming)
    X=X.apply(lemm)
    X=X.apply(clean_length)
    return X

"""Membaca dataset dan menerapkan proses one-hot-encoding dan membuat dataframe baru.

Dataset dapat didapatkan di : https://www.kaggle.com/datasets/atulanandjha/imdb-50k-movie-reviews-test-your-bert?select=test.csv
"""

import pandas as pd
df = pd.read_csv("imdb.csv")

sentiment = pd.get_dummies(df.sentiment)
df_baru = pd.concat([df,sentiment], axis=1)
df_baru = df_baru.drop(columns="sentiment")
df_baru['text'][1000]

"""Memasukkan value text kedalam variabel review dan value neg, pos kedalam variabel label"""

review = df_baru['text'].values
label = df_baru[['neg','pos']].values

"""Membagi dataset menjadi train set dan validation set dengan ukuran masing-masing 80% dan 20%."""

from sklearn.model_selection import train_test_split
review_latih, review_test, label_latih, label_test = train_test_split(review, label, test_size=0.2)

"""Mengubah setiap kata pada dataset ke dalam bilangan numerik dengan fungsi Tokenizer. Setelahnya, konversi setiap sampel menjadi sequence."""

from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
 
tokenizer = Tokenizer(num_words=2000, oov_token='x')
tokenizer.fit_on_texts(review_latih) 
tokenizer.fit_on_texts(review_test)
 
sekuens_latih = tokenizer.texts_to_sequences(review_latih)
sekuens_test = tokenizer.texts_to_sequences(review_test)
 
padded_latih = pad_sequences(sekuens_latih) 
padded_test = pad_sequences(sekuens_test)

"""Membangun model Sequential dengan Embedding dan LSTM."""

import tensorflow as tf
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim=2000, output_dim=128),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')
])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])

"""Membuat callbacks, jika akurasi mencapai 95% maka train model akan berhenti"""

# Berhenti ketika akurasi sudah 95%
class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('accuracy')> 0.95):
      print("Akurasi sudah mencapai 95%, Train berhenti")
      self.model.stop_training = True

callbacks = myCallback()

"""Latih model dengan model.fit dan menyimpannya ke dalam variabel history guna memudahkan proses plotting."""

num_epochs = 30
history = model.fit(padded_latih, 
                    label_latih, 
                    epochs=num_epochs, 
                    validation_data=(padded_test, label_test), 
                    verbose=2, 
                    callbacks=[callbacks])

"""Scatter plot Training dan Validation Accuracy"""

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Train Accuracy ')                
plt.plot(epochs, val_acc, 'b', label='Valid Accuracy')
plt.title('Train and Valid Accuracy')
plt.legend(loc=0)
plt.figure()                                                                      
plt.show()

plt.plot(epochs, loss, 'r', label='Train Loss ')                
plt.plot(epochs, val_loss, 'b', label='Valid Loss')
plt.title('Train and Valid Loss')
plt.legend(loc=0)
plt.figure()                                                                      
plt.show()